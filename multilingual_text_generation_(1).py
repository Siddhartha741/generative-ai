# -*- coding: utf-8 -*-
"""multilingual_text_generation (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Siddhartha741/generative-ai/blob/main/multilingual_text_generation%20(1).ipynb
"""

from transformers import pipeline

def translate_text_t5(prompt):
    translator = pipeline('translation_en_to_fr', model='t5-small')
    translated_text = translator(prompt, max_length=100)[0]['translation_text']
    print(translated_text)

"""english to french"""

prompt_text = "Translate the following sentence into French: i am fine"
translate_text_t5(prompt_text)

"""english to hindi"""

def translate_text_english_to_hindi(prompt):
    translator = pipeline('translation_en_to_hi', model='Helsinki-NLP/opus-mt-en-hi')
    translated_text = translator(prompt, max_length=100)[0]['translation_text']
    print(translated_text)

english_text = "Hello, how are you?"
translate_text_english_to_hindi(english_text)

"""hindi to english"""

def translate_text_hindi_to_english(prompt):
    translator = pipeline('translation_hi_to_en', model='Helsinki-NLP/opus-mt-hi-en')
    translated_text = translator(prompt, max_length=100)[0]['translation_text']
    print(translated_text)

hindi_text = "नमस्ते, आप कैसे हैं?"

translate_text_hindi_to_english(hindi_text)

"""spanish to english"""

def translate_text_spanish_to_english(prompt):
    translator = pipeline('translation_es_to_en', model='Helsinki-NLP/opus-mt-es-en')
    translated_text = translator(prompt, max_length=100)[0]['translation_text']
    print(translated_text)

spanish_text = "Hola, ¿cómo estás?"
translate_text_spanish_to_english(spanish_text)

"""german to english"""

def translate_text_german_to_english(prompt):
    translator = pipeline('translation_de_to_en', model='Helsinki-NLP/opus-mt-de-en')
    translated_text = translator(prompt, max_length=100)[0]['translation_text']
    print(translated_text)

german_text = "Guten Tag, wie geht es Ihnen?"
translate_text_german_to_english(german_text)

"""french to english"""

def translate_text_french_to_english(prompt):
    translator = pipeline('translation_fr_to_en', model='Helsinki-NLP/opus-mt-fr-en')
    translated_text = translator(prompt, max_length=100)[0]['translation_text']
    print(translated_text)

french_text = "Bonjour, comment ça va?"
translate_text_french_to_english(french_text)

"""TRANSFORMERS"""

!pip install transformers

from transformers import pipeline, set_seed

# Define the translation function
def translate_text(text, target_language='fr'):
    translation_pipeline = pipeline('translation_en_to_fr', model='t5-small')
    translated_text = translation_pipeline(text, max_length=100)[0]['translation_text']
    return translated_text

# Define the function to generate a concise response using GPT-2
def get_concise_response(prompt):
    generator = pipeline('text-generation', model='gpt2')
    set_seed(42)  # For reproducible results
    response = generator(prompt, max_length=50, num_return_sequences=1, pad_token_id=50256)[0]['generated_text']
    response = response.split('. ')[0] + '.' if '.' in response else response
    return response.strip()

# Define the function to handle a single interaction
def handle_interaction(prompt, target_language='fr'):
    # Get the GPT-2 response
    response = get_concise_response(prompt)

    # Translate the GPT-2 response
    translated_response = translate_text(response, target_language)

    return {
        "Original input": prompt,
        "GPT-2 response": response,
        "Translated response": translated_response
    }

# Example usage with a question
result = handle_interaction("What is your name?", target_language='fr')
print(result)

"""CHAT WITH GPT AND TEXT TRANSLATION IN MULTIPLE LAANGUAGES"""

from transformers import pipeline, set_seed

# Define the translation function
def translate_text(text, target_language='fr'):
    translation_pipeline = pipeline('translation_en_to_fr', model='t5-small')
    translated_text = translation_pipeline(text, max_length=100)[0]['translation_text']
    return translated_text

# Define the function to generate a concise response using GPT-2
def get_concise_response(prompt):
    generator = pipeline('text-generation', model='gpt2')
    set_seed(42)  # For reproducible results
    response = generator(prompt, max_length=50, num_return_sequences=1, pad_token_id=50256)[0]['generated_text']
    response = response.split('. ')[0] + '.' if '.' in response else response
    return response.strip()

# Define the function to handle a single interaction
def handle_interaction(prompt, target_language='fr'):
    # Get the GPT-2 response
    response = get_concise_response(prompt)

    # Translate the GPT-2 response
    translated_response = translate_text(response, target_language)

    return {
        "Original input": prompt,
        "GPT-2 response": response,
        "Translated response": translated_response
    }

# Interactive loop for user input
def interactive_chat(target_language='fr'):
    print("Welcome to the interactive chat! Type 'exit' to end the chat.")

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            print("Ending the chat. Goodbye!")
            break

        result = handle_interaction(user_input, target_language)
        print(f"GPT-2 response: {result['GPT-2 response']}")
        print(f"Translated response ({target_language}): {result['Translated response']}")

# Run the interactive chat
interactive_chat(target_language='fr')

from transformers import pipeline, set_seed

# Define the translation function for English to Hindi
def translate_text(text, target_language='hi'):
    translation_pipeline = pipeline('translation_en_to_hi', model='Helsinki-NLP/opus-mt-en-hi')
    translated_text = translation_pipeline(text, max_length=100)[0]['translation_text']
    return translated_text

# Define the function to generate a concise response using GPT-2
def get_concise_response(prompt):
    generator = pipeline('text-generation', model='gpt2')
    set_seed(42)  # For reproducible results
    response = generator(prompt, max_length=50, num_return_sequences=1, pad_token_id=50256)[0]['generated_text']
    response = response.split('. ')[0] + '.' if '.' in response else response
    return response.strip()

# Define the function to handle a single interaction
def handle_interaction(prompt, target_language='hi'):
    # Get the GPT-2 response
    response = get_concise_response(prompt)

    # Translate the GPT-2 response
    translated_response = translate_text(response, target_language)

    return {
        "Original input": prompt,
        "GPT-2 response": response,
        "Translated response": translated_response
    }

# Interactive loop for user input
def interactive_chat(target_language='hi'):
    print("Welcome to the interactive chat! Type 'exit' to end the chat.")

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            print("Ending the chat. Goodbye!")
            break

        result = handle_interaction(user_input, target_language)
        print(f"GPT-2 response: {result['GPT-2 response']}")
        print(f"Translated response ({target_language}): {result['Translated response']}")

# Run the interactive chat
interactive_chat(target_language='hi')